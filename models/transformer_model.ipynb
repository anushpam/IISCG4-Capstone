{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "b7692423-4852-4f76-b922-20ea70be61e4",
      "metadata": {
        "id": "b7692423-4852-4f76-b922-20ea70be61e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15b13555-a456-4b71-b291-bdbdda46073d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: data_preprocessing in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "Successfully installed keras-2.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              },
              "id": "8f7ceea7eb3e439fae14fb7b073e098f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install data_preprocessing\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1v1TIE2Tjff"
      },
      "id": "e1v1TIE2Tjff",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import *\n",
        "import tensorflow as tf\n",
        "import joblib, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tensorflow.keras.models import Model\n",
        "from data_preprocessing import *\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, LSTM, Attention, MultiHeadAttention, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle"
      ],
      "metadata": {
        "id": "VOudjI4jVxSa"
      },
      "id": "VOudjI4jVxSa",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "8d7a00a3-b35c-4c29-99d2-a88156ba0f35",
      "metadata": {
        "id": "8d7a00a3-b35c-4c29-99d2-a88156ba0f35"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(open('/content/Consolidated.xlsx', 'rb'), sheet_name='Consolidated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "828a5569-ee81-4bea-8c94-5c25b33e4505",
      "metadata": {
        "id": "828a5569-ee81-4bea-8c94-5c25b33e4505"
      },
      "outputs": [],
      "source": [
        "df_final_test = df.query('Foldername == \"fold1\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "7946cce0-dcc2-442a-a61e-c430bd6e4a93",
      "metadata": {
        "id": "7946cce0-dcc2-442a-a61e-c430bd6e4a93"
      },
      "outputs": [],
      "source": [
        "le = joblib.load('/content/labelEncoder.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "5f837b0d-124f-4c7d-8a67-ced61edab665",
      "metadata": {
        "id": "5f837b0d-124f-4c7d-8a67-ced61edab665"
      },
      "outputs": [],
      "source": [
        "num_classes = 4\n",
        "embedding_dim = 128\n",
        "num_heads = 2\n",
        "max_seq_length = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "17c01b6c-22a5-494f-9c7a-0d7b9d07cb6b",
      "metadata": {
        "id": "17c01b6c-22a5-494f-9c7a-0d7b9d07cb6b"
      },
      "outputs": [],
      "source": [
        "def pre_process_data(X, y, max_seq, num_classes, token_model_save=True):\n",
        "    tokenizer = Tokenizer()\n",
        "    if token_model_save:\n",
        "        tokenizer.fit_on_texts(X)\n",
        "        with open('saved_models/tokenizer.pickle', 'wb') as f:\n",
        "            pickle.dump(tokenizer, f)\n",
        "    else:\n",
        "        with open('saved_models/tokenizer.pickle', 'rb') as f:\n",
        "            tokenizer = pickle.load(f)\n",
        "    X_train_sequences = tokenizer.texts_to_sequences(X)\n",
        "    max_seq_length = 250  # Choose the maximum sequence length\n",
        "    X_train_padded = pad_sequences(X_train_sequences, maxlen=max_seq, padding='post')\n",
        "    target_labels = tf.keras.utils.to_categorical(le.transform(y), num_classes)\n",
        "    return X_train_padded, target_labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tf\n",
        "from keras.layers import LSTM, Dense, TimeDistributed, Dropout, RepeatVector, Input, Reshape, Flatten\n",
        "from tensorflow.keras.models import *\n",
        "import joblib\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # 1. Lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "    # 2. Removing special characters & punctuation\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "\n",
        "    # 3. Tokenization\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # 4. Stopword Removal\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # 5. Lemmatization (Change words to root form)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # 6. Joining tokens back into a string\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VK2nSwLAbXDR"
      },
      "id": "VK2nSwLAbXDR",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "f2f8f734-d49c-4988-ad93-59c572deb5c4",
      "metadata": {
        "id": "f2f8f734-d49c-4988-ad93-59c572deb5c4"
      },
      "outputs": [],
      "source": [
        "X, y = pre_process_data(df['Review'].apply(preprocess_text), df['Target'], max_seq_length, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "966cd967-6082-42d3-aecf-e4bdaf25d928",
      "metadata": {
        "id": "966cd967-6082-42d3-aecf-e4bdaf25d928"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "57ef5019-15c2-4434-8102-e15265600476",
      "metadata": {
        "id": "57ef5019-15c2-4434-8102-e15265600476"
      },
      "outputs": [],
      "source": [
        "def create_model(max_seq_length, embedding_dim, num_heads):\n",
        "    input_layer = Input(shape=(max_seq_length,))\n",
        "    embedding_layer = Embedding(input_dim=1500, output_dim=embedding_dim)(input_layer)\n",
        "    attention_layer = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(embedding_layer, embedding_layer)\n",
        "    pooling_layer = GlobalAveragePooling1D()(attention_layer)\n",
        "    dropout_layer = Dropout(0.1)(pooling_layer)\n",
        "    output_layer = Dense(4, activation='softmax')(dropout_layer)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "d1ed592f-5c03-4047-bb40-8f9a9bce1b5d",
      "metadata": {
        "id": "d1ed592f-5c03-4047-bb40-8f9a9bce1b5d"
      },
      "outputs": [],
      "source": [
        "model = create_model(max_seq_length, embedding_dim, num_heads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "f9aef64e-1a46-4011-afa4-58676e6111e8",
      "metadata": {
        "id": "f9aef64e-1a46-4011-afa4-58676e6111e8"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=tf.keras.metrics.F1Score(name='f1_score',average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "3ea3edb8-dded-4688-ae25-cffecdd2a81e",
      "metadata": {
        "id": "3ea3edb8-dded-4688-ae25-cffecdd2a81e",
        "outputId": "93036d46-ec70-469b-9679-153288959a4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 7s 122ms/step - loss: 1.3770 - f1_score: 0.2595 - val_loss: 1.3405 - val_f1_score: 0.2033\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 1.1814 - f1_score: 0.3218 - val_loss: 1.0122 - val_f1_score: 0.3451\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 4s 144ms/step - loss: 0.8607 - f1_score: 0.4999 - val_loss: 0.8148 - val_f1_score: 0.5136\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 5s 165ms/step - loss: 0.7530 - f1_score: 0.5408 - val_loss: 0.7628 - val_f1_score: 0.6139\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 4s 123ms/step - loss: 0.6889 - f1_score: 0.6184 - val_loss: 0.6831 - val_f1_score: 0.7257\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 3s 107ms/step - loss: 0.5309 - f1_score: 0.7992 - val_loss: 0.4869 - val_f1_score: 0.8277\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 0.2824 - f1_score: 0.9017 - val_loss: 0.3404 - val_f1_score: 0.8546\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1413 - f1_score: 0.9480 - val_loss: 0.2851 - val_f1_score: 0.9085\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 2s 73ms/step - loss: 0.0659 - f1_score: 0.9799 - val_loss: 0.3039 - val_f1_score: 0.9180\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 2s 52ms/step - loss: 0.0290 - f1_score: 0.9911 - val_loss: 0.2871 - val_f1_score: 0.9450\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78b999a0c430>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=64, shuffle=True, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "6513f5b2-7082-4be9-8185-8635de4e2574",
      "metadata": {
        "id": "6513f5b2-7082-4be9-8185-8635de4e2574",
        "outputId": "9202bc07-4f07-40e6-a72d-c9b8e9cb1cd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "062c16c6-d1ff-463f-9e85-a98eeb283176",
      "metadata": {
        "id": "062c16c6-d1ff-463f-9e85-a98eeb283176",
        "outputId": "8f107745-bb89-4e34-928e-d41610e51bd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9425526503456946"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "f1_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1), average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "e8dcf728-577d-4f6f-83cc-f1a85619638e",
      "metadata": {
        "id": "e8dcf728-577d-4f6f-83cc-f1a85619638e"
      },
      "outputs": [],
      "source": [
        "model.save('saved_models/transformer.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "7fa83d20-16a3-4905-8321-72065856ba8c",
      "metadata": {
        "id": "7fa83d20-16a3-4905-8321-72065856ba8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8710c7f4-baf1-483d-a5e1-180330a48fbd",
      "metadata": {
        "id": "8710c7f4-baf1-483d-a5e1-180330a48fbd"
      },
      "source": [
        "## Test model with unseen data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "23694741-3792-472a-980a-1dd9ed976ee7",
      "metadata": {
        "id": "23694741-3792-472a-980a-1dd9ed976ee7"
      },
      "outputs": [],
      "source": [
        "t_X , t_y = pre_process_data(df_final_test['Review'].apply(preprocess_text), df_final_test['Target'], max_seq_length, num_classes, token_model_save=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "b3290aeb-02de-4509-9e13-2eeb343687d1",
      "metadata": {
        "id": "b3290aeb-02de-4509-9e13-2eeb343687d1",
        "outputId": "e3f38b42-f6a4-47ef-f971-99c4c0996915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "l_model = tf.keras.models.load_model('saved_models/transformer.keras')\n",
        "predictions = l_model.predict(t_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "cd09e981-c370-4efb-8093-6d10c6a4cfa1",
      "metadata": {
        "id": "cd09e981-c370-4efb-8093-6d10c6a4cfa1",
        "outputId": "0a6316da-9327-491b-863f-695db2997704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.962570819803974"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "f1_score(np.argmax(t_y, axis=1), np.argmax(predictions, axis=1), average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "38023f4c-4604-4c3a-bca5-40c3bc35f457",
      "metadata": {
        "id": "38023f4c-4604-4c3a-bca5-40c3bc35f457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a79cf5-a393-4269-a379-421226fe8857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: adam, Hidden Units: 32, Mean Accuracy: 0.9925203919410706\n",
            "Optimizer: adam, Hidden Units: 64, Mean Accuracy: 0.9956803917884827\n",
            "Optimizer: adam, Hidden Units: 128, Mean Accuracy: 1.0\n",
            "Optimizer: rmsprop, Hidden Units: 32, Mean Accuracy: 1.0\n",
            "Optimizer: rmsprop, Hidden Units: 64, Mean Accuracy: 1.0\n",
            "Optimizer: rmsprop, Hidden Units: 128, Mean Accuracy: 1.0\n",
            "Best Parameters: {'optimizer': 'adam', 'hidden_units': 128}\n",
            "Best Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "optimizers = ['adam', 'rmsprop']\n",
        "hidden_units = [32, 64, 128]\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "for optimizer in optimizers:\n",
        "    for units in hidden_units:\n",
        "        # Create a Keras model with specified hyperparameters\n",
        "\n",
        "        # Perform cross-validation\n",
        "        kfold = KFold(n_splits=3, shuffle=True)\n",
        "        accuracies = []\n",
        "        for train_idx, val_idx in kfold.split(X_train):\n",
        "            X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "            model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, verbose=0)\n",
        "            _, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "            accuracies.append(accuracy)\n",
        "\n",
        "        mean_accuracy = np.mean(accuracies)\n",
        "        print(f\"Optimizer: {optimizer}, Hidden Units: {units}, Mean Accuracy: {mean_accuracy}\")\n",
        "\n",
        "        # Track the best hyperparameters\n",
        "        if mean_accuracy > best_accuracy:\n",
        "            best_accuracy = mean_accuracy\n",
        "            best_params = {'optimizer': optimizer, 'hidden_units': units}\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Accuracy:\", best_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = Sequential()\n",
        "best_model.add(Dense(128, activation='relu', input_shape=(1500,)))\n",
        "best_model.add(Dense(num_classes, activation='softmax'))\n",
        "best_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=tf.keras.metrics.F1Score(name='f1_score',average='macro'))"
      ],
      "metadata": {
        "id": "W2LuKxV8cWFD"
      },
      "id": "W2LuKxV8cWFD",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=64, shuffle=True, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7ZktR2idJF9",
        "outputId": "d1b26577-0b80-45a4-c12a-2aab867d3f11"
      },
      "id": "R7ZktR2idJF9",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 7.1306e-07 - f1_score: 1.0000 - val_loss: 3.2666e-07 - val_f1_score: 1.0000\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 5.7200e-07 - f1_score: 1.0000 - val_loss: 3.2387e-07 - val_f1_score: 1.0000\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 2s 48ms/step - loss: 6.9096e-07 - f1_score: 1.0000 - val_loss: 3.2200e-07 - val_f1_score: 1.0000\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 2s 69ms/step - loss: 4.6676e-07 - f1_score: 1.0000 - val_loss: 3.2037e-07 - val_f1_score: 1.0000\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 1s 41ms/step - loss: 5.2544e-07 - f1_score: 1.0000 - val_loss: 3.1944e-07 - val_f1_score: 1.0000\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 1s 41ms/step - loss: 5.1799e-07 - f1_score: 1.0000 - val_loss: 3.1572e-07 - val_f1_score: 1.0000\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 6.1554e-07 - f1_score: 1.0000 - val_loss: 3.1455e-07 - val_f1_score: 1.0000\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 1s 37ms/step - loss: 4.3720e-07 - f1_score: 1.0000 - val_loss: 3.1385e-07 - val_f1_score: 1.0000\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 1s 45ms/step - loss: 6.7658e-07 - f1_score: 1.0000 - val_loss: 3.1828e-07 - val_f1_score: 1.0000\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 4.1420e-07 - f1_score: 1.0000 - val_loss: 3.1735e-07 - val_f1_score: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78b9976f24a0>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5lpVN_2gJbI",
        "outputId": "3ade289f-2965-474a-8b4b-047db1257c95"
      },
      "id": "-5lpVN_2gJbI",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyNyZi_SigeA",
        "outputId": "d6618332-d945-4524-b172-753e0dee6884"
      },
      "id": "QyNyZi_SigeA",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('saved_models/transformer_updated.keras')"
      ],
      "metadata": {
        "id": "yMnf-CAijrPv"
      },
      "id": "yMnf-CAijrPv",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_X , t_y = pre_process_data(df_final_test['Review'].apply(preprocess_text), df_final_test['Target'], max_seq_length, num_classes, token_model_save=False)"
      ],
      "metadata": {
        "id": "XGd4yXc7l5fj"
      },
      "id": "XGd4yXc7l5fj",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_model = tf.keras.models.load_model('saved_models/transformer_updated.keras')\n",
        "predictions = l_model.predict(t_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPFvq748tOUI",
        "outputId": "4a5f1d4e-05dd-4266-b118-d6b7e2b0e24f"
      },
      "id": "CPFvq748tOUI",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(np.argmax(t_y, axis=1), np.argmax(predictions, axis=1), average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TFD-W2btRcU",
        "outputId": "22fb6e40-4d35-4904-9396-390b1fe77b5b"
      },
      "id": "1TFD-W2btRcU",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9843746337747568"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FwluAGv1tTWd"
      },
      "id": "FwluAGv1tTWd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}